{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "from functools import reduce\n",
    "#from zonal_stats import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move working directory to Data folder\n",
    "os.chdir('/Tesis/Datos') \n",
    "os.getcwd()\n",
    "pkls = '/Tesis/Codes/pkls/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metropolitan areas\n",
    "\n",
    "The metropolitan areas used for this work are those defined by the CONAPO in 2015.\n",
    "This file was downloaded from:\n",
    "\n",
    "https://datos.gob.mx/busca/dataset/distribucion-territorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CVE_ZM</th>\n",
       "      <th>NOM_ZM</th>\n",
       "      <th>CVE_ENT</th>\n",
       "      <th>NOM_ENT</th>\n",
       "      <th>CVE_MUN</th>\n",
       "      <th>NOM_MUN</th>\n",
       "      <th>POB_2015</th>\n",
       "      <th>2015</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.01</td>\n",
       "      <td>Aguascalientes</td>\n",
       "      <td>1</td>\n",
       "      <td>Aguascalientes</td>\n",
       "      <td>1001</td>\n",
       "      <td>Aguascalientes</td>\n",
       "      <td>877190</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.01</td>\n",
       "      <td>Aguascalientes</td>\n",
       "      <td>1</td>\n",
       "      <td>Aguascalientes</td>\n",
       "      <td>1005</td>\n",
       "      <td>Jesús María</td>\n",
       "      <td>120405</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.01</td>\n",
       "      <td>Aguascalientes</td>\n",
       "      <td>1</td>\n",
       "      <td>Aguascalientes</td>\n",
       "      <td>1011</td>\n",
       "      <td>San Francisco de los Romo</td>\n",
       "      <td>46454</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.01</td>\n",
       "      <td>Ensenada</td>\n",
       "      <td>2</td>\n",
       "      <td>Baja California</td>\n",
       "      <td>2001</td>\n",
       "      <td>Ensenada</td>\n",
       "      <td>486639</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.02</td>\n",
       "      <td>Mexicali</td>\n",
       "      <td>2</td>\n",
       "      <td>Baja California</td>\n",
       "      <td>2002</td>\n",
       "      <td>Mexicali</td>\n",
       "      <td>988417</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CVE_ZM          NOM_ZM  CVE_ENT          NOM_ENT  CVE_MUN  \\\n",
       "0    1.01  Aguascalientes        1   Aguascalientes     1001   \n",
       "1    1.01  Aguascalientes        1   Aguascalientes     1005   \n",
       "2    1.01  Aguascalientes        1   Aguascalientes     1011   \n",
       "3    2.01        Ensenada        2  Baja California     2001   \n",
       "4    2.02        Mexicali        2  Baja California     2002   \n",
       "\n",
       "                     NOM_MUN  POB_2015   2015  \n",
       "0             Aguascalientes    877190   True  \n",
       "1                Jesús María    120405   True  \n",
       "2  San Francisco de los Romo     46454   True  \n",
       "3                   Ensenada    486639  False  \n",
       "4                   Mexicali    988417   True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read 2015 and 2010 csv files and extract Metropolis\n",
    "ZM_2015 = pd.read_csv(\"Zonas metropolitanas\\ZM_2015.csv\", encoding='latin-1', usecols=list(range(7)))              \n",
    "ZM_2010 = pd.read_csv(\"Zonas metropolitanas\\Base_delimitacionZM_00-10.csv\", usecols=[2,21])\n",
    "\n",
    "# Select 2010 values and set \"2015\" to False if new Metropoli\n",
    "ZM_2010 = ZM_2010.loc[ZM_2010['AÑO']==2010]\n",
    "ZM_2015['2015'] = ZM_2015['CVE_MUN'].isin(ZM_2010['CVE_MUN'])\n",
    "del ZM_2010\n",
    "\n",
    "ZM_2015.to_pickle(pkls + 'ZM_2015.pkl')\n",
    "\n",
    "ZM_2015.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature\n",
    "\n",
    "This section takes the average seasonal temperature for every municipality of the Metropolitan zones.\n",
    "To do so, a raster with the average temperature from 1902 to 2011 is used. Using zonal stats, the mean per municipality is taken for every month and aggregated by season.\n",
    "\n",
    "Raster: http://atlasclimatico.unam.mx/atlas/kml/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a shapefiles for municipalities if there isn't one\n",
    "fname = \"shapefiles/MUN/MUN_ZM.shp\"\n",
    "if not os.path.exists(fname):\n",
    "        # Get individual municipalities shape files in directory\n",
    "    mun_geo_path = 'Marco Geoestadistico/conjunto de datos'\n",
    "    mun_files = []\n",
    "    # r=root, d=directories, f = files\n",
    "    for r, d, f in os.walk(mun_geo_path):\n",
    "        for file in f:\n",
    "            if 'mun.shp' in file:\n",
    "                mun_files.append(os.path.join(r, file))\n",
    "    # Put all files in a list to concatenate it\n",
    "    mun_list = []\n",
    "    for file in mun_files:\n",
    "        mun_x = gpd.read_file(file)\n",
    "        mun_list.append(mun_x)\n",
    "        \n",
    "    # Concatenate    \n",
    "    mun = pd.concat(mun_list, sort=False)\n",
    "    mun.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    # Fix Municipalities code\n",
    "    mun['CVE_MUN'] = (mun['CVE_ENT'] + mun['CVE_MUN']).astype(np.int64)\n",
    "    # Take municipalities within metropolitan zones\n",
    "    mun_ZM = mun.loc[mun['CVE_MUN'].isin(ZM_2015['CVE_MUN'])].copy()\n",
    "\n",
    "    # Create shapefile\n",
    "    mun_ZM.to_file(fname)\n",
    "    print(fname + 'created')\n",
    "\n",
    "# Create a df with the mean temperature in the municipality\n",
    "vector_path = fname\n",
    "#vector_path = \"shapefiles/MUN/MUN.shp\"\n",
    "temp_list = []\n",
    "for i in range(1,13):\n",
    "    raster_path = 'Temperatura/TemperaturaMedia_mensual_raster/tmedia_'+ str(i) + '/tmedia_' + str(i) + '/Geotiff/tmed_' + str(i) + '.tif'\n",
    "    temp_x = (pd.DataFrame.from_dict(zonal_stats(vector_path, raster_path, 'population','CVE_MUN', nodata_value=-3.4028234663852886e+38)))\n",
    "    temp_x.rename(columns={'mean':str(i)}, inplace=True)\n",
    "    temp_list.append(temp_x)\n",
    "    \n",
    "# Merge months in one df\n",
    "temp_merged = reduce(lambda  left,right: pd.merge(left,right,on=['CVE_MUN']), temp_list)\n",
    "temp_merged['CVE_MUN'] = temp_merged['CVE_MUN'].astype(np.int64)\n",
    "temp_merged.to_pickle(pkls + 'temp_months_mun.pkl')\n",
    "\n",
    "# Reduce the months to seasons\n",
    "temp_season = pd.DataFrame()\n",
    "temp_season['CVE_MUN'] = temp_merged['CVE_MUN'].astype(np.int64)\n",
    "temp_season['Winter'] = temp_merged.loc[:,['1','2','12']].sum(axis = 1)/3 \n",
    "temp_season['Spring'] = temp_merged.loc[:,'3':'5'].sum(axis = 1)/3 \n",
    "temp_season['Summer'] = temp_merged.loc[:,'6':'8'].sum(axis = 1)/3 \n",
    "temp_season['Fall'] = temp_merged.loc[:,'9':'11'].sum(axis = 1)/3\n",
    "temp_season['max'] = temp_merged.loc[:,'4':'9'].max(axis=1)\n",
    "\n",
    "temp_season.to_pickle(pkls + 'temp_season_mun.pkl')\n",
    "\n",
    "# Merge Temp with ZM dataframe\n",
    "ZM_2015 = ZM_2015.merge(temp_season, how='left', on=['CVE_MUN'])\n",
    "ZM_2015.reset_index(inplace=True, drop=True)\n",
    "\n",
    "del temp_season\n",
    "\n",
    "ZM_2015.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tempeture for tariff map CFE\n",
    "This cell creates a temperature shapefile according to CFE's tariffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge municipalities shapefile with min and max temperatures\n",
    "temp_merged['CVE_MUN'] = temp_merged['CVE_MUN'].astype(np.int64)\n",
    "mun = gpd.read_file(\"shapefiles/MUN/MUN.shp\")\n",
    "mun_tarifa = mun.merge(temp_merged[['CVE_MUN','4','5','6','7','8','9']], on=['CVE_MUN'])\n",
    "mun_tarifa['min'] = temp_merged.loc[:,'4':'9'].min(axis=1)\n",
    "mun_tarifa['max'] = temp_merged.loc[:,'4':'9'].max(axis=1)\n",
    "mun_tarifa.to_file(\"shapefiles/MUN/Temperatura/MUN_tarifa.shp\") \n",
    "\n",
    "del temp_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Censo de Población y Vivienda 2010\n",
    "\n",
    "The CPV 2010 is the last complete census available. The files are available for each state. The highest level of disaggregation corresponds to \"manzanas\" (blocks). These files are read and added to the Metropolis dataframe.\n",
    "\n",
    "These files were downloaded from:\n",
    "https://www.inegi.org.mx/programas/ccpv/2010/default.html#Datos_abiertos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to take from Censo de Población y Vivienda\n",
    "cpyv_col = [0,2] + list(range(4,12)) + [29,32,35,38,41,44,26,48,54] + [108,129] + \\\n",
    "            [132,135,138,141] + list(range(157,165)) + [171,172] + list(range(189,198))\n",
    "\n",
    "# Read Censo de Población y Vivienda files\n",
    "CPV_path = 'Censo Poblacion y Vivienda 2010/AGEB/conjunto_de_datos'\n",
    "\n",
    "# Locate filenames\n",
    "CPV_files = []\n",
    "for r, d, f in os.walk(CPV_path):\n",
    "    for file in f:\n",
    "        CPV_files.append(os.path.join(r, file))\n",
    "\n",
    "# Put all csv files in a list to concatenate it\n",
    "CPVlist = []\n",
    "for file in CPV_files:\n",
    "    CPV_ent = pd.read_csv(file, usecols=cpyv_col, dtype={'ageb': str}, na_values=['*','N/D'])\n",
    "    CPVlist.append(CPV_ent)\n",
    "CPV = pd.concat(CPVlist)\n",
    "\n",
    "# Create a new CVE_MUN index\n",
    "CPV['mun'] = CPV['entidad']*1000 + CPV['mun']\n",
    "\n",
    "# Set names for the merging\n",
    "CPV.rename(columns={'entidad':'CVE_ENT', 'loc':'CVE_LOC', 'mun':'CVE_MUN'}, inplace=True)\n",
    "\n",
    "# Create missing age range\n",
    "CPV['p_25a59'] = CPV['p_18ymas']-CPV['p_18a24']-CPV['p_60ymas']\n",
    "\n",
    "# Organize columns\n",
    "cols = CPV.columns.tolist()\n",
    "cols = cols[:cols.index('p_60ymas')] + ['p_25a59'] + cols[cols.index('p_60ymas'):-1]\n",
    "CPV = CPV[cols]\n",
    "\n",
    "# Merge CPV with ZM dataframe\n",
    "ZM_CPV = ZM_2015.merge(CPV, how='left', on=['CVE_MUN','CVE_ENT'])\n",
    "ZM_CPV.reset_index(inplace=True, drop=True)\n",
    "\n",
    "del CPV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grado de marginación urbana\n",
    "\n",
    "The stage of urban marginalization is available at AGEB level, the stages are:\n",
    "- Very low\n",
    "- Low\n",
    "- Medium\n",
    "- High\n",
    "- Very high\n",
    "\n",
    "The data is added to our previous Metropolis dataframe\n",
    "\n",
    "These files were downloaded from:\n",
    "https://datos.gob.mx/busca/dataset/indice-de-marginacion-carencias-poblacionales-por-localidad-municipio-y-entidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to take from Grado de marginación urbana\n",
    "GMU_cols = [6,30,31,32] \n",
    "\n",
    "# File path\n",
    "GMU_file = 'Marginacion\\Base_marginacion_AGEB_00-10.csv'\n",
    "\n",
    "# Read GMU file and take year 2010\n",
    "GMU = pd.read_csv(GMU_file, usecols=GMU_cols, encoding='latin-1')\n",
    "GMU = GMU.loc[GMU['AÑO']==2010].reset_index(drop=True)\n",
    "\n",
    "# Explode CVE_AGEB into columns to create matching index to ZM_2015\n",
    "GMU['CVE_ENT'] = GMU['CVE_AGEB'].str[:-11].astype(np.int64)\n",
    "GMU['CVE_MUN'] = GMU['CVE_AGEB'].str[:-8].astype(np.int64)\n",
    "GMU['CVE_LOC'] = GMU['CVE_AGEB'].str[-8:-4].astype(np.int64)\n",
    "GMU['ageb'] = GMU['CVE_AGEB'].str[-4:]\n",
    "del GMU['CVE_AGEB'], GMU['AÑO']\n",
    "\n",
    "# Fix negative values in IMU\n",
    "GMU.loc[(GMU['GMU']=='Muy bajo') | (GMU['GMU']=='Bajo') | (GMU['GMU']=='Medio'),'IMU'] = -GMU['IMU']\n",
    "\n",
    "GMU.to_pickle(pkls + 'GMU.pkl')\n",
    "\n",
    "# Join ZM_2015 with GMU\n",
    "ZM_GMU = ZM_CPV.merge(GMU, how='left', on=['CVE_ENT', 'CVE_MUN', 'CVE_LOC', 'ageb'])\n",
    "del GMU\n",
    "\n",
    "ZM_GMU.to_pickle(pkls + 'ZM_GMU.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean and prepare data for regression\n",
    "This cell clean the data and fill nans in order to use the CPV, temperature, and IMU variables as regressors in the regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take columns of interest\n",
    "cols = ['CVE_ZM','CVE_ENT','CVE_MUN','CVE_LOC','ageb','mza','Summer','pobtot',\n",
    "        'tothog','prom_ocup','IMU','graproes','pocupada'] + ZM_GMU.columns[18:31].tolist() \n",
    "\n",
    "zm = ZM_GMU.loc[ZM_GMU.mza!=0,cols] # Ignore summary rows\n",
    "zm.rename(columns={'prom_ocup':'tot_integ','graproes':'nivelaprob','pocupada':'ocupados'}, inplace=True) # rename columns\n",
    "\n",
    "# fill nans in gender\n",
    "zm['pobmas'].fillna(zm['pobtot']-zm['pobfem'], inplace=True)\n",
    "zm['pobfem'].fillna(zm['pobtot']-zm['pobmas'], inplace=True)\n",
    "\n",
    "# fill nans using given population\n",
    "zm['tothog'].fillna(round(zm['pobtot']/zm['tot_integ']), inplace=True)\n",
    "zm['tot_integ'].fillna(zm['pobtot']/zm['tothog'], inplace=True)\n",
    "\n",
    "# Turn false 0s to nans\n",
    "a = (zm['tot_integ']==0) & (zm['pobtot']!=0)\n",
    "\n",
    "zm.loc[a,'tothog'] = np.nan\n",
    "zm.loc[a,'tot_integ'] = np.nan\n",
    "\n",
    "# fill nans using means\n",
    "colgroup = ['CVE_ZM','CVE_ENT','CVE_MUN','CVE_LOC','ageb']\n",
    "\n",
    "zm['tothog'].fillna(-(-zm['pobtot']//zm.groupby(colgroup)['tot_integ'].transform(lambda x: x.fillna(x.mean()))), inplace=True)\n",
    "zm['tothog'].fillna(-(-zm['pobtot']//zm.groupby('CVE_MUN')['tot_integ'].transform(lambda x: x.fillna(x.mean()))), inplace=True)\n",
    "zm['tot_integ'].fillna(zm['pobtot']/zm['tothog'], inplace=True)\n",
    "\n",
    "# Create new fields\n",
    "zm['h_m_sexo'] = (zm['pobmas'] - zm['pobfem'])/zm['pobtot']\n",
    "zm['ma_me_edad'] = (zm['p_18ymas']*2 - zm['pobtot'])/zm['pobtot']\n",
    "zm['ocupados'] = zm['ocupados']/zm['pobtot']\n",
    "\n",
    "zm['edad'] = (zm['p_0a2'].fillna(0)*1 + zm['p_3a5'].fillna(0)*4 + zm['p_6a11'].fillna(0)*8.5 + zm['p_12a14'].fillna(0)*13 +\\\n",
    "            zm['p_15a17'].fillna(0)*16 + zm['p_18a24'].fillna(0)*21 + zm['p_25a59'].fillna(0)*38 +\\\n",
    "            (zm['p_60ymas'].fillna(0)-zm['pob65_mas'].fillna(0))*62.5 + zm['pob65_mas'].fillna(0)*76 +\\\n",
    "            (zm['p_18ymas'].fillna(0)-(zm['p_18a24'].fillna(0) + zm['p_25a59'].fillna(0)+zm['p_60ymas'].fillna(0)))*41)/\\\n",
    "            (zm['p_0a2'].fillna(0) + zm['p_3a5'].fillna(0) + zm['p_6a11'].fillna(0)+zm['p_12a14'].fillna(0) + zm['p_15a17'].fillna(0) +\\\n",
    "            zm['p_18a24'].fillna(0) + zm['p_25a59'].fillna(0) + zm['p_60ymas'].fillna(0) +\\\n",
    "            (zm['p_18ymas'].fillna(0)-(zm['p_18a24'].fillna(0)+zm['p_25a59'].fillna(0)+zm['p_60ymas'].fillna(0))))\n",
    "\n",
    "zm.drop(ZM_GMU.columns[18:31].tolist() , axis=1, inplace=True)\n",
    "\n",
    "# set 0s in 0 pobtot\n",
    "zm.loc[zm['pobtot']==0,['nivelaprob','ocupados','h_m_sexo','ma_me_edad','edad']] = 0\n",
    "zm.loc[(zm.edad==0) & (zm.pobtot!=0), ['nivelaprob','ocupados','ma_me_edad','edad']] = np.nan\n",
    "\n",
    "# fill nans using means\n",
    "colnans = ['IMU','nivelaprob','ocupados','h_m_sexo','ma_me_edad','edad']\n",
    "colgroup = ['CVE_ZM','CVE_ENT','CVE_MUN','CVE_LOC','ageb']\n",
    "zm[colnans] = zm.groupby(colgroup)[colnans].transform(lambda x: x.fillna(x.mean()))\n",
    "zm[colnans] = zm.groupby('CVE_MUN')[colnans].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "zm.loc[(zm.edad==0) & (zm.pobtot!=0), ['nivelaprob','ocupados','ma_me_edad','edad']] = np.nan\n",
    "\n",
    "# fill nans using means\n",
    "colnans = ['IMU','nivelaprob','ocupados','h_m_sexo','ma_me_edad','edad']\n",
    "colgroup = ['CVE_ZM','CVE_ENT','CVE_MUN','CVE_LOC','ageb']\n",
    "zm[colnans] = zm.groupby('CVE_MUN')[colnans].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "zm.loc[zm['pobtot']==0,['nivelaprob','ocupados','h_m_sexo','ma_me_edad','edad']] = np.nan\n",
    "\n",
    "zm.to_pickle(pkls + 'ZM_REG1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encuesta Nacional de Ingresos y Gastos de los Hogares 2016 \n",
    "The ENIGH gives statistical data related to expenses and income. It also includes data related to the number of vehicles, electronic and electric devices, and an updated estimate of the population.\n",
    "\n",
    "This data is not added yet to de previous dataframe as it is available at a lower level and it has to be first processed.\n",
    "\n",
    "These files were downloaded from:\n",
    "\n",
    "https://www.inegi.org.mx/programas/enigh/nc/2016/default.html#Microdatos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concentrador hogar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to take from Concentradorhogar\n",
    "concentrador_cols = [0,1,2,3,5] + list(range(7,24)) + [57]\n",
    "\n",
    "# Read concentrador file\n",
    "concentrador_file = 'Ingresos y Gastos de los Hogares/2016/concentradohogar.csv'\n",
    "concentrador = pd.read_csv(concentrador_file, usecols=concentrador_cols, na_values=' ')\n",
    "\n",
    "# Change ageb format\n",
    "concentrador['ageb'] = concentrador['ageb'].str[:3] + concentrador['ageb'].str[-1]\n",
    "\n",
    "# Change female to 0 (male 1)\n",
    "concentrador.loc[concentrador['sexo_jefe']==2,'sexo_jefe'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folioviv</th>\n",
       "      <th>foliohog</th>\n",
       "      <th>ubica_geo</th>\n",
       "      <th>ageb</th>\n",
       "      <th>est_socio</th>\n",
       "      <th>upm</th>\n",
       "      <th>factor</th>\n",
       "      <th>clase_hog</th>\n",
       "      <th>sexo_jefe</th>\n",
       "      <th>edad_jefe</th>\n",
       "      <th>educa_jefe</th>\n",
       "      <th>tot_integ</th>\n",
       "      <th>hombres</th>\n",
       "      <th>mujeres</th>\n",
       "      <th>mayores</th>\n",
       "      <th>menores</th>\n",
       "      <th>p12_64</th>\n",
       "      <th>p65mas</th>\n",
       "      <th>ocupados</th>\n",
       "      <th>percep_ing</th>\n",
       "      <th>perc_ocupa</th>\n",
       "      <th>ing_cor</th>\n",
       "      <th>gasto_mon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100003801</td>\n",
       "      <td>1</td>\n",
       "      <td>10010001</td>\n",
       "      <td>0233</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>247</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100696.70</td>\n",
       "      <td>46599.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003802</td>\n",
       "      <td>1</td>\n",
       "      <td>10010001</td>\n",
       "      <td>0233</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>247</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>146616.16</td>\n",
       "      <td>82427.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100003803</td>\n",
       "      <td>1</td>\n",
       "      <td>10010001</td>\n",
       "      <td>0233</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>247</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>94622.95</td>\n",
       "      <td>54792.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100003804</td>\n",
       "      <td>1</td>\n",
       "      <td>10010001</td>\n",
       "      <td>0233</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>247</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>58278.65</td>\n",
       "      <td>42452.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100003805</td>\n",
       "      <td>1</td>\n",
       "      <td>10010001</td>\n",
       "      <td>0233</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>247</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57295.07</td>\n",
       "      <td>47589.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70306</th>\n",
       "      <td>3260801324</td>\n",
       "      <td>1</td>\n",
       "      <td>320580001</td>\n",
       "      <td>0072</td>\n",
       "      <td>2</td>\n",
       "      <td>79010</td>\n",
       "      <td>198</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>24940.72</td>\n",
       "      <td>18564.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70307</th>\n",
       "      <td>3260801902</td>\n",
       "      <td>1</td>\n",
       "      <td>320580001</td>\n",
       "      <td>002A</td>\n",
       "      <td>2</td>\n",
       "      <td>79010</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19814.80</td>\n",
       "      <td>4371.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70308</th>\n",
       "      <td>3260801904</td>\n",
       "      <td>1</td>\n",
       "      <td>320580001</td>\n",
       "      <td>002A</td>\n",
       "      <td>2</td>\n",
       "      <td>79010</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23160.72</td>\n",
       "      <td>4102.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70309</th>\n",
       "      <td>3260801905</td>\n",
       "      <td>1</td>\n",
       "      <td>320580001</td>\n",
       "      <td>002A</td>\n",
       "      <td>2</td>\n",
       "      <td>79010</td>\n",
       "      <td>198</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23385.60</td>\n",
       "      <td>28360.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70310</th>\n",
       "      <td>3260801906</td>\n",
       "      <td>1</td>\n",
       "      <td>320580001</td>\n",
       "      <td>002A</td>\n",
       "      <td>2</td>\n",
       "      <td>79010</td>\n",
       "      <td>198</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>15888.51</td>\n",
       "      <td>12278.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70311 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         folioviv  foliohog  ubica_geo  ageb  est_socio    upm  factor  \\\n",
       "0       100003801         1   10010001  0233          4     10     247   \n",
       "1       100003802         1   10010001  0233          4     10     247   \n",
       "2       100003803         1   10010001  0233          4     10     247   \n",
       "3       100003804         1   10010001  0233          4     10     247   \n",
       "4       100003805         1   10010001  0233          4     10     247   \n",
       "...           ...       ...        ...   ...        ...    ...     ...   \n",
       "70306  3260801324         1  320580001  0072          2  79010     198   \n",
       "70307  3260801902         1  320580001  002A          2  79010     198   \n",
       "70308  3260801904         1  320580001  002A          2  79010     198   \n",
       "70309  3260801905         1  320580001  002A          2  79010     198   \n",
       "70310  3260801906         1  320580001  002A          2  79010     198   \n",
       "\n",
       "       clase_hog  sexo_jefe  edad_jefe  educa_jefe  tot_integ  hombres  \\\n",
       "0              2          1         33          10          2        1   \n",
       "1              2          1         29          10          2        1   \n",
       "2              2          1         47          10          6        2   \n",
       "3              3          0         29          11          3        0   \n",
       "4              2          1         55          10          2        2   \n",
       "...          ...        ...        ...         ...        ...      ...   \n",
       "70306          3          1         49           3          4        2   \n",
       "70307          1          0         74           1          1        0   \n",
       "70308          1          1         77           3          1        1   \n",
       "70309          2          1         67           9          3        1   \n",
       "70310          3          1         62           5          5        2   \n",
       "\n",
       "       mujeres  mayores  menores  p12_64  p65mas  ocupados  percep_ing  \\\n",
       "0            1        2        0       2       0         2           2   \n",
       "1            1        2        0       2       0         2           2   \n",
       "2            4        3        3       3       0         1           1   \n",
       "3            3        3        0       3       0         2           3   \n",
       "4            0        2        0       2       0         1           1   \n",
       "...        ...      ...      ...     ...     ...       ...         ...   \n",
       "70306        2        3        1       3       0         2           3   \n",
       "70307        1        1        0       0       1         0           1   \n",
       "70308        0        1        0       0       1         1           1   \n",
       "70309        2        2        1       1       1         0           1   \n",
       "70310        3        4        1       4       0         3           3   \n",
       "\n",
       "       perc_ocupa    ing_cor  gasto_mon  \n",
       "0               2  100696.70   46599.96  \n",
       "1               2  146616.16   82427.75  \n",
       "2               1   94622.95   54792.51  \n",
       "3               2   58278.65   42452.37  \n",
       "4               1   57295.07   47589.29  \n",
       "...           ...        ...        ...  \n",
       "70306           2   24940.72   18564.33  \n",
       "70307           0   19814.80    4371.23  \n",
       "70308           1   23160.72    4102.37  \n",
       "70309           0   23385.60   28360.73  \n",
       "70310           3   15888.51   12278.79  \n",
       "\n",
       "[70311 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concentrador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Población\n",
    "This section calculates values for age and education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to take from poblacion\n",
    "poblacion_cols = [0,1,2,5,40]\n",
    "\n",
    "# Read poblacion file\n",
    "poblacion_file = 'Ingresos y Gastos de los Hogares/2016/poblacion.csv'\n",
    "poblacion = pd.read_csv(poblacion_file, usecols=poblacion_cols, na_values=' ')\n",
    "\n",
    "# Get mean age\n",
    "pop_edad = poblacion.groupby(['folioviv','foliohog'], sort=False, as_index=False)['edad'].mean()\n",
    "\n",
    "# Transform to escolaridad\n",
    "dic_edu = {0:0,1:0,2:6,3:9,4:12,5:15,6:15,7:16,8:18,9:21}\n",
    "poblacion['nivelaprob'] = poblacion['nivelaprob'].map(dic_edu)\n",
    "# Get mean education of pop > 15 y\n",
    "pop_edu = poblacion.loc[poblacion['edad']>=15].groupby(['folioviv','foliohog'], sort=False, as_index=False)['nivelaprob'].mean()\n",
    "# Get mean education whole pop to fill houses with no >15\n",
    "pop_edu_men15 = poblacion.groupby(['folioviv','foliohog'], sort=False, as_index=False)['nivelaprob'].mean()\n",
    "\n",
    "# merge\n",
    "pop = pop_edad.merge(pop_edu, on=['folioviv','foliohog'], how='left')\n",
    "pop = pop.merge(pop_edu_men15, on=['folioviv','foliohog'], how='left')\n",
    "\n",
    "pop['nivelaprob_x'] = pop['nivelaprob_x'].fillna(pop['nivelaprob_y'])\n",
    "pop.drop('nivelaprob_y', axis=1, inplace=True)\n",
    "pop.rename(columns={'nivelaprob_x':'nivelaprob'}, inplace=True)\n",
    "\n",
    "concentrador = concentrador.merge(pop, on=['folioviv','foliohog'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viviendas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to take from Viviendas\n",
    "viviendas_cols = [0,5,21,22,23,24,27,28,29] +list(range(46,53))\n",
    "\n",
    "# Read viviendas file\n",
    "viviendas_file = 'Ingresos y Gastos de los Hogares/2016/viviendas.csv'\n",
    "vivienda = pd.read_csv(viviendas_file, usecols=viviendas_cols, na_values=' ')\n",
    "\n",
    "# Change false from 2 to 0\n",
    "vivienda.loc[vivienda['calent_sol']==2,'calent_sol'] = 0\n",
    "vivienda.loc[vivienda['calent_gas']==2,'calent_gas'] = 0\n",
    "vivienda.loc[vivienda['medidor_luz']==2,'medidor_luz'] = 0\n",
    "vivienda.loc[vivienda['bomba_agua']==2,'bomba_agua'] = 0\n",
    "vivienda.loc[vivienda['tanque_gas']==2,'tanque_gas'] = 0\n",
    "vivienda.loc[vivienda['aire_acond']==2,'aire_acond'] = 0\n",
    "vivienda.loc[vivienda['calefacc']==2,'calefacc'] = 0\n",
    "\n",
    "# merge renta and estim_pago\n",
    "vivienda['renta'] = vivienda['renta'].fillna(vivienda['estim_pago'])\n",
    "del vivienda['estim_pago']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hogares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to take from Hogares\n",
    "hogares_cols = [0,1] + list(range(39,47)) + list(range(57,97))\n",
    "\n",
    "# Read Hogares file\n",
    "hogares_file = 'Ingresos y Gastos de los Hogares/2016/hogares.csv'\n",
    "hogares = pd.read_csv(hogares_file, usecols=hogares_cols, na_values=[' ','&',-1])\n",
    "\n",
    "# Merge all kind of automobile\n",
    "hogares['num_vehiculos'] = hogares['num_auto'] + hogares['num_van'] + hogares['num_pickup']\n",
    "hogares['anio_vehiculos'] = hogares[['anio_auto', 'anio_van', 'anio_pickup']].mean(axis = 1, skipna = True).round()\n",
    "\n",
    "hogares.drop(['num_auto','anio_auto','num_van','anio_van','num_pickup','anio_pickup'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gastos\n",
    "Combustibles vehiculos\n",
    "F007,F008,F009\n",
    "\n",
    "Combustibles\n",
    "G009-G014\n",
    "\n",
    "Electricidad\n",
    "R001\n",
    "\n",
    "Gas\n",
    "R003\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to take from gastos\n",
    "gastos_cols = [0,1,2,23]\n",
    "\n",
    "# Expenses' keys\n",
    "claves = ['R001','R003','G009','G010','G011','G012','G013','G014']\n",
    "dic_cves = {'R001':'ele', 'R003':'gas', 'G009':'glp', 'G010':'pet', 'G011':'die', 'G012':'car', 'G013':'len', 'G014':'heat'}\n",
    "\n",
    "# Read gastos file\n",
    "gastos_file = 'Ingresos y Gastos de los Hogares/2016/gastoshogar.csv'\n",
    "gastos = pd.read_csv(gastos_file, usecols=gastos_cols, na_values=' ')\n",
    "\n",
    "gastos.dropna(subset=['gasto_tri'], inplace=True)\n",
    "\n",
    "# Convert every type of expense into a column\n",
    "gastolist = []\n",
    "for clave in claves:\n",
    "    gasto_x = gastos.loc[gastos['clave']==clave].copy()\n",
    "    gasto_x.rename(columns={'gasto_tri':'gasto_tri_' + dic_cves[clave]}, inplace=True)\n",
    "    gasto_x.drop(['clave'], axis=1, inplace=True)\n",
    "    gastolist.append(gasto_x)\n",
    "del gastos\n",
    "\n",
    "# merge all the expenses\n",
    "gastos = reduce(lambda  left,right: pd.merge(left,right, on=['folioviv','foliohog'], how='outer'), gastolist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENIGH 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all tables\n",
    "gast_ing = pd.merge(pd.merge(pd.merge(concentrador,vivienda, on='folioviv'), \n",
    "                             hogares, on=['folioviv','foliohog']), gastos, on=['folioviv','foliohog'])\n",
    "\n",
    "del concentrador, vivienda, hogares, gastos\n",
    "\n",
    "# Explode ubica_geop into columns to create matching index to ZM_2015\n",
    "gast_ing['ubica_geo'] = gast_ing['ubica_geo'].astype(str) \n",
    "\n",
    "gast_ing['CVE_ENT'] = gast_ing['ubica_geo'].str[:-7].astype(np.int64)\n",
    "gast_ing['CVE_MUN'] = gast_ing['ubica_geo'].str[:-4].astype(np.int64)\n",
    "gast_ing['CVE_LOC'] = gast_ing['ubica_geo'].str[-4:].astype(np.int64)\n",
    "del gast_ing['ubica_geo']\n",
    "\n",
    "# Select areas within Metropolitan zones\n",
    "gast_ing_ZM = gast_ing.loc[gast_ing['CVE_MUN'].isin(ZM_2015['CVE_MUN'])]\n",
    "\n",
    "gast_ing_ZM.to_pickle(pkls + 'gast_ing_ZM.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DENUEs\n",
    "The Directorio Estadístico Nacional de Unidades Económicas (DENUE) is a directory of the active econimic units within the country, including idetifiers, location, economic activity, size, etc. The information of 2015 was taken as it is the closest registered to the CPV2010.\n",
    "\n",
    "These files were downloaded from:\n",
    "https://www.inegi.org.mx/app/descarga/?ti=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to take from DENUEs\n",
    "denues_cols = [0,1,3,4,5,22,26,28,30,32,33,35] \n",
    "\n",
    "# Get csv files in directory\n",
    "denues_path = 'DENUE/2015'\n",
    "denues_files = []\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(denues_path):\n",
    "    for file in f:\n",
    "        if '.csv' in file:\n",
    "            denues_files.append(os.path.join(r, file))\n",
    "            \n",
    "# Put all csv files in a list to concatenate it\n",
    "denues_list = []\n",
    "for file in denues_files:\n",
    "    denues_x = pd.read_csv(file, usecols=denues_cols, dtype={'Área geoestadística básica ': str}, na_values=[' '])\n",
    "    denues_list.append(denues_x)\n",
    "\n",
    "denues = pd.concat(denues_list)\n",
    "\n",
    "# change column names\n",
    "denues.rename(columns={'Nombre de la Unidad Económica':'nom_ue', 'Código de la clase de actividad SCIAN':'cod_scian',\n",
    "                      'Nombre de clase de la actividad':'actividad', 'Descripcion estrato personal ocupado':'num_personal',\n",
    "                      'Tipo centro comercial':'centro_com', 'Área geoestadística básica ':'ageb'}, inplace=True)\n",
    "\n",
    "# change municipio code\n",
    "denues['Clave municipio'] = denues['Clave municipio'] + denues['Clave entidad']*1000\n",
    "\n",
    "# Create dataframe with DENUEs within the metropolitan zones\n",
    "denues_ZM = denues.loc[denues['Clave municipio'].isin(ZM_2015['CVE_MUN'])]\n",
    "\n",
    "denues_ZM.to_pickle(pkls + 'denues_ZM.pkl')\n",
    "\n",
    "denues_ZM.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pkls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denues_ZM = pd.read_pickle(pkls + 'denues_ZM.pkl')\n",
    "gast_ing_ZM = pd.read_pickle(pkls + 'gast_ing_ZM.pkl')\n",
    "ZM_2015 = pd.read_pickle(pkls + 'ZM_2015.pkl')\n",
    "ZM_GMU = pd.read_pickle(pkls + 'ZM_GMU.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shapefiles\n",
    "This section merge the shapefiles of the Marco Geoestadistico into sigle shapefiles, not necessary if the shapefiles already exist\n",
    "\n",
    "## Municipalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get csv files in directory\n",
    "mun_geo_path = 'Marco Geoestadistico/conjunto de datos'\n",
    "mun_files = []\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(mun_geo_path):\n",
    "    for file in f:\n",
    "        if 'mun.shp' in file:\n",
    "            mun_files.append(os.path.join(r, file))\n",
    "\n",
    "# Put all csv files in a list to concatenate it            \n",
    "mun_list = []\n",
    "for file in mun_files:\n",
    "    mun_x = gpd.read_file(file)\n",
    "    mun_list.append(mun_x)\n",
    "\n",
    "mun = pd.concat(mun_list)\n",
    "\n",
    "mun.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Fix CVE_MUN columns\n",
    "mun['CVE_MUN'] = mun['CVEGEO'].astype(np.int64)\n",
    "del mun['CVEGEO']\n",
    "\n",
    "mun.to_file(\"shapefiles/MUN/MUN.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metropolitan areas: Municipalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take metropolitan municipalities\n",
    "mun_ZM = mun.loc[mun['CVE_MUN'].isin(ZM_2015['CVE_MUN'])].copy()\n",
    "\n",
    "# Merge Geodataframe with metropolitan zones dataframe\n",
    "mun_ZM = mun_ZM.merge(ZM_2015[['CVE_MUN','CVE_ZM','NOM_ZM']], on='CVE_MUN')\n",
    "\n",
    "# Dissolve into metropolitan zones\n",
    "ZM = mun_ZM.dissolve(by='CVE_ZM', aggfunc='first')\n",
    "ZM.drop(['CVE_ENT', 'CVE_MUN', 'NOMGEO'], axis=1, inplace=True)\n",
    "\n",
    "ZM.reset_index(inplace=True)\n",
    "\n",
    "ZM.to_file(\"shapefiles/ZM/ZM.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metropolitan areas: Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get csv files in directory\n",
    "mzn_geo_path = 'Marco Geoestadistico/conjunto de datos'\n",
    "mzn_files = []\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(mzn_geo_path):\n",
    "    for file in f:\n",
    "        if 'm.shp' in file and len(file)==7:\n",
    "            mzn_files.append(os.path.join(r, file))\n",
    "\n",
    "# Put all csv files in a list to concatenate it\n",
    "mnz_list = []\n",
    "for file in mzn_files:\n",
    "    mnz_x = gpd.read_file(file)\n",
    "    mnz_list.append(mnz_x)\n",
    "\n",
    "mnz = pd.concat(mnz_list)\n",
    "mnz.reset_index(inplace=True, drop=True)\n",
    "\n",
    "mnz['CVE_MUN'] = (mnz['CVE_ENT'] + mnz['CVE_MUN']).astype(np.int64)\n",
    "mnz['CVE_ENT'] = mnz['CVE_ENT'].astype(np.int64)\n",
    "mnz['CVE_LOC'] = mnz['CVE_LOC'].astype(np.int64)\n",
    "\n",
    "# Take metropolitan municipalities\n",
    "mzn_ZM = mnz.loc[mnz['CVE_MUN'].isin(ZM_2015['CVE_MUN'])].copy()\n",
    "\n",
    "# Merge Geodataframe with metropolitan zones dataframe\n",
    "mzn_ZM = mzn_ZM.merge(ZM_2015[['CVE_MUN','CVE_ZM','NOM_ZM']], on='CVE_MUN')\n",
    "\n",
    "mzn_ZM.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mzn_ZM.to_file(\"shapefiles/manzanas/mzn_ZM.shp\")\n",
    "mzn_ZM.to_pickle(pkls + 'mza_shp.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
